{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Data Audit & EDA for Research\n",
    "\n",
    "**Goal:** Understand exactly what data we have, its quality, and prepare for RQ1 experiments  \n",
    "**Research Question 1:** Does decomposing environmental prediction into specialized agents outperform monolithic models?\n",
    "\n",
    "---\n",
    "\n",
    "## Datasets:\n",
    "1. `ml_ready_data.csv` — 53K rows, 10 features (pre-processed)\n",
    "2. `in_situ/LUBW_BW_measurements...csv` — 49K rows, 23 features (raw in-situ)\n",
    "3. `satellite/*.csv` — 8.7K rows (spectral indices)\n",
    "4. `lake_data/*.json` — yearly lake data with bloom indicators\n",
    "\n",
    "## Outputs:\n",
    "- Data quality report\n",
    "- Clean, merged research dataset\n",
    "- Bloom labels (binary + continuous)\n",
    "- Train/val/test splits (temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path('/Users/futurediary/Desktop/A.I. Agents/ERAY_HEIDELBERG')\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "HARMONIZED_DIR = DATA_DIR / 'harmonized'\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1A: ML-ready data\n",
    "ml_data = pd.read_csv(PROCESSED_DIR / 'ml_ready_data.csv', parse_dates=['timestamp'])\n",
    "print(f'ml_ready_data: {ml_data.shape[0]:,} rows x {ml_data.shape[1]} cols')\n",
    "print(f'  Date range: {ml_data[\"timestamp\"].min()} → {ml_data[\"timestamp\"].max()}')\n",
    "print(f'  Lakes: {ml_data[\"lake\"].nunique()} unique → {ml_data[\"lake\"].value_counts().head(10).to_dict()}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1B: In-situ measurements\n",
    "insitu = pd.read_csv(RAW_DIR / 'in_situ' / 'LUBW_BW_measurements_Seen_Wasserqualitaet_Extracted.csv',\n",
    "                     parse_dates=['timestamp'])\n",
    "print(f'in_situ: {insitu.shape[0]:,} rows x {insitu.shape[1]} cols')\n",
    "print(f'  Date range: {insitu[\"timestamp\"].min()} → {insitu[\"timestamp\"].max()}')\n",
    "print(f'  Lakes: {insitu[\"location_name\"].nunique()} unique')\n",
    "print(f'  Columns: {list(insitu.columns)}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1C: Satellite data (combine all CSVs)\n",
    "sat_files = sorted(glob.glob(str(RAW_DIR / 'satellite' / '*.csv')))\n",
    "sat_dfs = []\n",
    "for f in sat_files:\n",
    "    df = pd.read_csv(f, parse_dates=['acquisition_date'])\n",
    "    df['source_file'] = Path(f).name\n",
    "    sat_dfs.append(df)\n",
    "    print(f'  {Path(f).name}: {len(df):,} rows')\n",
    "\n",
    "satellite = pd.concat(sat_dfs, ignore_index=True)\n",
    "print(f'\\nSatellite combined: {satellite.shape[0]:,} rows x {satellite.shape[1]} cols')\n",
    "print(f'  Date range: {satellite[\"acquisition_date\"].min()} → {satellite[\"acquisition_date\"].max()}')\n",
    "print(f'  Lakes: {satellite[\"lake_name\"].nunique()} → {satellite[\"lake_name\"].value_counts().to_dict()}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D: Lake JSON data (has bloom labels!)\n",
    "lake_json_files = sorted(glob.glob(str(RAW_DIR / 'lake_data' / '*.json')))\n",
    "lake_records = []\n",
    "for f in lake_json_files:\n",
    "    if 'current_week' not in f:\n",
    "        with open(f) as fh:\n",
    "            data = json.load(fh)\n",
    "            for rec in data:\n",
    "                rec['source_file'] = Path(f).name\n",
    "            lake_records.extend(data)\n",
    "            print(f'  {Path(f).name}: {len(data)} records')\n",
    "\n",
    "# Flatten nested JSON\n",
    "lake_flat = []\n",
    "for rec in lake_records:\n",
    "    flat = {\n",
    "        'date': rec.get('date'),\n",
    "        'lake': rec.get('lake'),\n",
    "        'source': rec.get('source'),\n",
    "        'quality_score': rec.get('quality_score'),\n",
    "        'source_file': rec.get('source_file'),\n",
    "    }\n",
    "    # Flatten parameters\n",
    "    for k, v in rec.get('parameters', {}).items():\n",
    "        flat[f'param_{k}'] = v\n",
    "    # Flatten HAB indicators\n",
    "    for k, v in rec.get('habs_indicators', {}).items():\n",
    "        flat[f'hab_{k}'] = v\n",
    "    lake_flat.append(flat)\n",
    "\n",
    "lake_data = pd.DataFrame(lake_flat)\n",
    "lake_data['date'] = pd.to_datetime(lake_data['date'])\n",
    "print(f'\\nLake JSON combined: {lake_data.shape[0]:,} rows')\n",
    "print(f'  Date range: {lake_data[\"date\"].min()} → {lake_data[\"date\"].max()}')\n",
    "print(f'  Lakes: {lake_data[\"lake\"].nunique()} → {lake_data[\"lake\"].value_counts().to_dict()}')\n",
    "print(f'  Bloom statuses: {lake_data[\"hab_bloom_status\"].value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Quality Audit\n",
    "Check for synthetic data, missing values, suspicious patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2A: ML-ready data quality\n",
    "print('=' * 60)\n",
    "print('ML-READY DATA QUALITY AUDIT')\n",
    "print('=' * 60)\n",
    "\n",
    "feature_cols = ['chlorophyll_a', 'water_temperature', 'turbidity', 'dissolved_oxygen',\n",
    "                'ph', 'total_nitrogen', 'total_phosphorus', 'solar_radiation',\n",
    "                'wind_speed', 'precipitation']\n",
    "\n",
    "for col in feature_cols:\n",
    "    zeros = (ml_data[col] == 0).sum()\n",
    "    nulls = ml_data[col].isna().sum()\n",
    "    unique = ml_data[col].nunique()\n",
    "    flag = '⚠️ SUSPICIOUS' if zeros / len(ml_data) > 0.5 else '✓'\n",
    "    print(f'  {col:25s} | zeros: {zeros:6d} ({zeros/len(ml_data)*100:5.1f}%) | nulls: {nulls:5d} | unique: {unique:6d} | {flag}')\n",
    "\n",
    "# Check lake name quality\n",
    "print(f'\\n  Lake column issues:')\n",
    "print(f'    Empty/null: {ml_data[\"lake\"].isna().sum()}')\n",
    "print(f'    \"object\" as lake name: {(ml_data[\"lake\"] == \"object\").sum()}')\n",
    "print(f'    Unique valid lakes: {ml_data[ml_data[\"lake\"] != \"object\"][\"lake\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2B: In-situ data quality\n",
    "print('=' * 60)\n",
    "print('IN-SITU DATA QUALITY AUDIT')\n",
    "print('=' * 60)\n",
    "\n",
    "insitu_features = ['chlorophyll_a', 'turbidity', 'dissolved_oxygen', 'ph',\n",
    "                   'conductivity', 'temperature', 'wind_speed', 'air_temperature', 'humidity']\n",
    "\n",
    "for col in insitu_features:\n",
    "    if col in insitu.columns:\n",
    "        zeros = (insitu[col] == 0).sum()\n",
    "        nulls = insitu[col].isna().sum()\n",
    "        mn, mx = insitu[col].min(), insitu[col].max()\n",
    "        print(f'  {col:25s} | range: [{mn:.2f}, {mx:.2f}] | zeros: {zeros:5d} | nulls: {nulls:5d}')\n",
    "\n",
    "print(f'\\n  Data sources: {insitu[\"data_source\"].value_counts().to_dict()}')\n",
    "print(f'  Locations: {insitu[\"location_name\"].value_counts().head(10).to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2C: Cross-dataset consistency check\n",
    "print('=' * 60)\n",
    "print('CROSS-DATASET CONSISTENCY')\n",
    "print('=' * 60)\n",
    "\n",
    "# Compare chlorophyll_a distributions across sources\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "axes[0].hist(ml_data['chlorophyll_a'].dropna(), bins=50, alpha=0.7, color='steelblue')\n",
    "axes[0].set_title(f'ml_ready: chlorophyll_a\\nμ={ml_data[\"chlorophyll_a\"].mean():.2f}, σ={ml_data[\"chlorophyll_a\"].std():.2f}')\n",
    "axes[0].set_xlabel('chlorophyll_a (μg/L)')\n",
    "\n",
    "axes[1].hist(insitu['chlorophyll_a'].dropna(), bins=50, alpha=0.7, color='coral')\n",
    "axes[1].set_title(f'in_situ: chlorophyll_a\\nμ={insitu[\"chlorophyll_a\"].mean():.2f}, σ={insitu[\"chlorophyll_a\"].std():.2f}')\n",
    "axes[1].set_xlabel('chlorophyll_a (μg/L)')\n",
    "\n",
    "axes[2].hist(satellite['chlorophyll_index'].dropna(), bins=50, alpha=0.7, color='seagreen')\n",
    "axes[2].set_title(f'satellite: chlorophyll_index\\nμ={satellite[\"chlorophyll_index\"].mean():.2f}, σ={satellite[\"chlorophyll_index\"].std():.2f}')\n",
    "axes[2].set_xlabel('chlorophyll_index')\n",
    "\n",
    "axes[3].hist(lake_data['param_chlorophyll_a'].dropna(), bins=50, alpha=0.7, color='orchid')\n",
    "axes[3].set_title(f'lake_json: chlorophyll_a\\nμ={lake_data[\"param_chlorophyll_a\"].mean():.2f}, σ={lake_data[\"param_chlorophyll_a\"].std():.2f}')\n",
    "axes[3].set_xlabel('chlorophyll_a (μg/L)')\n",
    "\n",
    "plt.suptitle('Chlorophyll-a Distribution Across All Data Sources', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Temporal Coverage Analysis\n",
    "Which lakes have data, for which time periods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3A: Temporal heatmap - records per lake per month\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# ML-ready data\n",
    "ml_valid = ml_data[ml_data['lake'] != 'object'].copy()\n",
    "if len(ml_valid) > 0:\n",
    "    ml_valid['month'] = ml_valid['timestamp'].dt.to_period('M').astype(str)\n",
    "    pivot = ml_valid.groupby(['lake', 'month']).size().unstack(fill_value=0)\n",
    "    sns.heatmap(pivot, ax=axes[0, 0], cmap='YlOrRd', cbar_kws={'label': 'Count'})\n",
    "    axes[0, 0].set_title('ML-Ready Data: Records per Lake/Month')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# In-situ data\n",
    "insitu_copy = insitu.copy()\n",
    "insitu_copy['month'] = insitu_copy['timestamp'].dt.to_period('M').astype(str)\n",
    "pivot2 = insitu_copy.groupby(['location_name', 'month']).size().unstack(fill_value=0)\n",
    "sns.heatmap(pivot2, ax=axes[0, 1], cmap='YlOrRd', cbar_kws={'label': 'Count'})\n",
    "axes[0, 1].set_title('In-Situ: Records per Location/Month')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Satellite data\n",
    "sat_copy = satellite.copy()\n",
    "sat_copy['month'] = sat_copy['acquisition_date'].dt.to_period('M').astype(str)\n",
    "pivot3 = sat_copy.groupby(['lake_name', 'month']).size().unstack(fill_value=0)\n",
    "sns.heatmap(pivot3, ax=axes[1, 0], cmap='YlOrRd', cbar_kws={'label': 'Count'})\n",
    "axes[1, 0].set_title('Satellite: Records per Lake/Month')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Lake JSON data\n",
    "lake_copy = lake_data.copy()\n",
    "lake_copy['month'] = lake_copy['date'].dt.to_period('M').astype(str)\n",
    "pivot4 = lake_copy.groupby(['lake', 'month']).size().unstack(fill_value=0)\n",
    "sns.heatmap(pivot4, ax=axes[1, 1], cmap='YlOrRd', cbar_kws={'label': 'Count'})\n",
    "axes[1, 1].set_title('Lake JSON: Records per Lake/Month')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('Temporal Coverage Across All Data Sources', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Feature Distributions & Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4A: Feature distributions for in-situ data (richest source)\n",
    "insitu_numeric = insitu[['chlorophyll_a', 'turbidity', 'dissolved_oxygen', 'ph',\n",
    "                         'temperature', 'conductivity', 'wind_speed', 'air_temperature', 'humidity']].copy()\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "for i, col in enumerate(insitu_numeric.columns):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    insitu_numeric[col].dropna().hist(bins=50, ax=ax, alpha=0.7, color='steelblue', edgecolor='white')\n",
    "    ax.set_title(f'{col}\\nμ={insitu_numeric[col].mean():.2f}, σ={insitu_numeric[col].std():.2f}')\n",
    "    ax.axvline(insitu_numeric[col].median(), color='red', linestyle='--', alpha=0.7, label='median')\n",
    "\n",
    "plt.suptitle('In-Situ Feature Distributions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4B: Correlation matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# In-situ correlations\n",
    "corr1 = insitu_numeric.corr()\n",
    "mask1 = np.triu(np.ones_like(corr1, dtype=bool))\n",
    "sns.heatmap(corr1, mask=mask1, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            ax=axes[0], vmin=-1, vmax=1, square=True)\n",
    "axes[0].set_title('In-Situ Feature Correlations')\n",
    "\n",
    "# ML-ready correlations\n",
    "ml_numeric = ml_data[feature_cols].copy()\n",
    "corr2 = ml_numeric.corr()\n",
    "mask2 = np.triu(np.ones_like(corr2, dtype=bool))\n",
    "sns.heatmap(corr2, mask=mask2, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            ax=axes[1], vmin=-1, vmax=1, square=True)\n",
    "axes[1].set_title('ML-Ready Feature Correlations')\n",
    "\n",
    "plt.suptitle('Feature Correlation Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Bloom Label Analysis\n",
    "Examine existing bloom indicators from lake JSON data & create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5A: Bloom indicators from lake JSON\n",
    "print('=' * 60)\n",
    "print('BLOOM LABEL ANALYSIS (Lake JSON Data)')\n",
    "print('=' * 60)\n",
    "\n",
    "print(f'\\nBloom probability distribution:')\n",
    "print(lake_data['hab_bloom_probability'].describe())\n",
    "\n",
    "print(f'\\nBloom status distribution:')\n",
    "print(lake_data['hab_bloom_status'].value_counts())\n",
    "\n",
    "print(f'\\nCyanobacteria density distribution:')\n",
    "print(lake_data['hab_cyanobacteria_density'].describe())\n",
    "\n",
    "print(f'\\nToxin levels distribution:')\n",
    "print(lake_data['hab_toxin_levels'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5B: Visualize bloom distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Bloom probability\n",
    "lake_data['hab_bloom_probability'].hist(bins=30, ax=axes[0, 0], color='crimson', alpha=0.7, edgecolor='white')\n",
    "axes[0, 0].set_title('Bloom Probability Distribution')\n",
    "axes[0, 0].axvline(0.5, color='black', linestyle='--', label='threshold=0.5')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Bloom status\n",
    "lake_data['hab_bloom_status'].value_counts().plot.bar(ax=axes[0, 1], color='steelblue', edgecolor='white')\n",
    "axes[0, 1].set_title('Bloom Status Counts')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Cyanobacteria density\n",
    "lake_data['hab_cyanobacteria_density'].hist(bins=30, ax=axes[1, 0], color='seagreen', alpha=0.7, edgecolor='white')\n",
    "axes[1, 0].set_title('Cyanobacteria Density')\n",
    "\n",
    "# Bloom probability by lake\n",
    "lake_data.boxplot(column='hab_bloom_probability', by='lake', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Bloom Probability by Lake')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "plt.suptitle('')  # remove default title\n",
    "\n",
    "plt.suptitle('Bloom Indicator Analysis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5C: Create binary bloom labels using multiple strategies\n",
    "print('=' * 60)\n",
    "print('LABEL STRATEGY COMPARISON')\n",
    "print('=' * 60)\n",
    "\n",
    "# Strategy 1: Threshold on bloom_probability (from lake JSON)\n",
    "lake_data['label_prob50'] = (lake_data['hab_bloom_probability'] >= 0.5).astype(int)\n",
    "lake_data['label_prob30'] = (lake_data['hab_bloom_probability'] >= 0.3).astype(int)\n",
    "\n",
    "# Strategy 2: Bloom status (categorical)\n",
    "status_map = {'None': 0, 'Low': 0, 'Moderate': 1, 'High': 1, 'Critical': 1}\n",
    "lake_data['label_status'] = lake_data['hab_bloom_status'].map(status_map).fillna(0).astype(int)\n",
    "\n",
    "# Strategy 3: Chlorophyll threshold (standard approach)\n",
    "lake_data['label_chl20'] = (lake_data['param_chlorophyll_a'] > 20).astype(int)\n",
    "lake_data['label_chl10'] = (lake_data['param_chlorophyll_a'] > 10).astype(int)\n",
    "\n",
    "# Compare label strategies\n",
    "label_cols = ['label_prob50', 'label_prob30', 'label_status', 'label_chl20', 'label_chl10']\n",
    "for col in label_cols:\n",
    "    pos = lake_data[col].sum()\n",
    "    total = len(lake_data)\n",
    "    print(f'  {col:20s} | positive: {pos:5d}/{total} ({pos/total*100:5.1f}%) | ratio: 1:{total//max(pos,1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Build Unified Research Dataset\n",
    "Merge in-situ + satellite + bloom labels into one clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6A: Prepare in-situ data as primary source\n",
    "# It has the richest feature set (23 cols)\n",
    "research_insitu = insitu[['location_name', 'timestamp', 'latitude', 'longitude', 'station_id',\n",
    "                           'chlorophyll_a', 'turbidity', 'dissolved_oxygen', 'ph',\n",
    "                           'temperature', 'conductivity', 'wind_speed', 'air_temperature',\n",
    "                           'humidity', 'quality_score', 'data_source', 'notes']].copy()\n",
    "\n",
    "# Standardize lake names for merging\n",
    "research_insitu['lake'] = research_insitu['location_name'].str.split(' - ').str[0].str.strip()\n",
    "research_insitu['date'] = research_insitu['timestamp'].dt.date\n",
    "\n",
    "print(f'In-situ prepared: {len(research_insitu):,} rows')\n",
    "print(f'Lakes: {research_insitu[\"lake\"].value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6B: Aggregate to daily level per lake (multiple measurements per day)\n",
    "daily_insitu = research_insitu.groupby(['lake', 'date']).agg({\n",
    "    'chlorophyll_a': 'mean',\n",
    "    'turbidity': 'mean',\n",
    "    'dissolved_oxygen': 'mean',\n",
    "    'ph': 'mean',\n",
    "    'temperature': 'mean',\n",
    "    'conductivity': 'mean',\n",
    "    'wind_speed': 'mean',\n",
    "    'air_temperature': 'mean',\n",
    "    'humidity': 'mean',\n",
    "    'latitude': 'first',\n",
    "    'longitude': 'first',\n",
    "    'quality_score': 'mean',\n",
    "}).reset_index()\n",
    "\n",
    "daily_insitu['date'] = pd.to_datetime(daily_insitu['date'])\n",
    "print(f'Daily aggregated: {len(daily_insitu):,} rows')\n",
    "print(daily_insitu.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6C: Merge satellite data (nearest date per lake)\n",
    "# Prepare satellite features\n",
    "sat_features = satellite[['lake_name', 'acquisition_date', 'ndvi', 'surface_temperature',\n",
    "                           'chlorophyll_index', 'turbidity_index', 'cloud_coverage',\n",
    "                           'reflectance_blue', 'reflectance_green', 'reflectance_red',\n",
    "                           'reflectance_nir']].copy()\n",
    "sat_features = sat_features.rename(columns={'lake_name': 'lake', 'acquisition_date': 'date'})\n",
    "sat_features['date'] = sat_features['date'].dt.normalize()\n",
    "\n",
    "# Daily aggregate for satellite\n",
    "daily_sat = sat_features.groupby(['lake', 'date']).agg({\n",
    "    'ndvi': 'mean',\n",
    "    'surface_temperature': 'mean',\n",
    "    'chlorophyll_index': 'mean',\n",
    "    'turbidity_index': 'mean',\n",
    "    'cloud_coverage': 'mean',\n",
    "    'reflectance_blue': 'mean',\n",
    "    'reflectance_green': 'mean',\n",
    "    'reflectance_red': 'mean',\n",
    "    'reflectance_nir': 'mean',\n",
    "}).reset_index()\n",
    "\n",
    "print(f'Daily satellite: {len(daily_sat):,} rows')\n",
    "print(f'Lakes: {daily_sat[\"lake\"].value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6D: Merge bloom labels from lake JSON\n",
    "lake_labels = lake_data[['date', 'lake', 'hab_bloom_probability', 'hab_bloom_status',\n",
    "                          'hab_cyanobacteria_density', 'hab_toxin_levels',\n",
    "                          'param_chlorophyll_a']].copy()\n",
    "lake_labels['date'] = lake_labels['date'].dt.normalize()\n",
    "\n",
    "# Daily aggregate\n",
    "daily_labels = lake_labels.groupby(['lake', 'date']).agg({\n",
    "    'hab_bloom_probability': 'mean',\n",
    "    'hab_cyanobacteria_density': 'mean',\n",
    "    'hab_toxin_levels': 'mean',\n",
    "    'hab_bloom_status': 'first',\n",
    "}).reset_index()\n",
    "\n",
    "print(f'Daily labels: {len(daily_labels):,} rows')\n",
    "print(f'Lakes: {daily_labels[\"lake\"].value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6E: Merge everything\n",
    "# Start with in-situ as base, merge satellite and labels\n",
    "research_df = daily_insitu.copy()\n",
    "\n",
    "# Merge satellite (on lake + date, allowing some date tolerance with merge_asof)\n",
    "research_df = research_df.sort_values('date')\n",
    "daily_sat_sorted = daily_sat.sort_values('date')\n",
    "\n",
    "merged_parts = []\n",
    "for lake in research_df['lake'].unique():\n",
    "    left = research_df[research_df['lake'] == lake].copy()\n",
    "    right = daily_sat_sorted[daily_sat_sorted['lake'] == lake].copy()\n",
    "    if len(right) > 0:\n",
    "        merged = pd.merge_asof(left, right.drop(columns=['lake']),\n",
    "                               on='date', tolerance=pd.Timedelta('3D'),\n",
    "                               direction='nearest')\n",
    "    else:\n",
    "        merged = left\n",
    "    merged_parts.append(merged)\n",
    "\n",
    "research_df = pd.concat(merged_parts, ignore_index=True)\n",
    "\n",
    "# Merge bloom labels\n",
    "daily_labels_sorted = daily_labels.sort_values('date')\n",
    "merged_parts2 = []\n",
    "for lake in research_df['lake'].unique():\n",
    "    left = research_df[research_df['lake'] == lake].sort_values('date').copy()\n",
    "    right = daily_labels_sorted[daily_labels_sorted['lake'] == lake].copy()\n",
    "    if len(right) > 0:\n",
    "        merged = pd.merge_asof(left, right.drop(columns=['lake']),\n",
    "                               on='date', tolerance=pd.Timedelta('7D'),\n",
    "                               direction='nearest')\n",
    "    else:\n",
    "        merged = left\n",
    "    merged_parts2.append(merged)\n",
    "\n",
    "research_df = pd.concat(merged_parts2, ignore_index=True)\n",
    "\n",
    "print(f'\\n{\"=\" * 60}')\n",
    "print(f'UNIFIED RESEARCH DATASET')\n",
    "print(f'{\"=\" * 60}')\n",
    "print(f'Shape: {research_df.shape}')\n",
    "print(f'Columns: {list(research_df.columns)}')\n",
    "print(f'Lakes: {research_df[\"lake\"].value_counts().to_dict()}')\n",
    "print(f'Date range: {research_df[\"date\"].min()} → {research_df[\"date\"].max()}')\n",
    "print(f'\\nNull counts:')\n",
    "print(research_df.isnull().sum().sort_values(ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Create Bloom Labels for Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7A: Binary bloom label — use bloom_probability if available, else chlorophyll threshold\n",
    "def create_bloom_label(row, threshold=0.5):\n",
    "    \"\"\"Multi-criteria bloom label.\"\"\"\n",
    "    # Priority 1: Use bloom_probability from monitoring data\n",
    "    if pd.notna(row.get('hab_bloom_probability')):\n",
    "        return int(row['hab_bloom_probability'] >= threshold)\n",
    "    # Priority 2: Chlorophyll-based threshold (WHO guideline: 10 μg/L moderate, 50 μg/L high)\n",
    "    chl = row.get('chlorophyll_a', np.nan)\n",
    "    temp = row.get('temperature', np.nan)\n",
    "    if pd.notna(chl):\n",
    "        if chl > 20:\n",
    "            return 1\n",
    "        if chl > 10 and pd.notna(temp) and temp > 18:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "research_df['bloom_label'] = research_df.apply(create_bloom_label, axis=1)\n",
    "\n",
    "# Continuous target (for regression)\n",
    "research_df['bloom_risk'] = research_df['hab_bloom_probability'].fillna(\n",
    "    research_df['chlorophyll_a'].clip(0, 50) / 50  # normalize chl to 0-1 as proxy\n",
    ")\n",
    "\n",
    "pos = research_df['bloom_label'].sum()\n",
    "total = len(research_df)\n",
    "print(f'Bloom label distribution: {pos} positive / {total} total ({pos/total*100:.1f}%)')\n",
    "print(f'Bloom risk (continuous): mean={research_df[\"bloom_risk\"].mean():.3f}, std={research_df[\"bloom_risk\"].std():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7B: Visualize label quality\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Label balance\n",
    "research_df['bloom_label'].value_counts().plot.bar(ax=axes[0], color=['steelblue', 'crimson'], edgecolor='white')\n",
    "axes[0].set_title('Binary Label Balance')\n",
    "axes[0].set_xticklabels(['No Bloom (0)', 'Bloom (1)'], rotation=0)\n",
    "\n",
    "# Risk distribution\n",
    "research_df['bloom_risk'].hist(bins=30, ax=axes[1], color='orchid', alpha=0.7, edgecolor='white')\n",
    "axes[1].set_title('Continuous Bloom Risk Distribution')\n",
    "axes[1].axvline(0.5, color='black', linestyle='--')\n",
    "\n",
    "# Bloom rate per lake\n",
    "bloom_by_lake = research_df.groupby('lake')['bloom_label'].mean().sort_values(ascending=False)\n",
    "bloom_by_lake.plot.bar(ax=axes[2], color='seagreen', edgecolor='white')\n",
    "axes[2].set_title('Bloom Rate by Lake')\n",
    "axes[2].set_ylabel('Fraction with bloom=1')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('Bloom Label Quality Assessment', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Train/Val/Test Split (Temporal)\n",
    "**Critical**: Use temporal split, NOT random, to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8A: Temporal split\n",
    "research_df = research_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Determine split points based on actual date range\n",
    "date_range = research_df['date'].max() - research_df['date'].min()\n",
    "train_end = research_df['date'].min() + pd.Timedelta(days=int(date_range.days * 0.7))\n",
    "val_end = research_df['date'].min() + pd.Timedelta(days=int(date_range.days * 0.85))\n",
    "\n",
    "train = research_df[research_df['date'] <= train_end]\n",
    "val = research_df[(research_df['date'] > train_end) & (research_df['date'] <= val_end)]\n",
    "test = research_df[research_df['date'] > val_end]\n",
    "\n",
    "print(f'Temporal Split:')\n",
    "print(f'  Train: {len(train):,} rows | {train[\"date\"].min()} → {train[\"date\"].max()} | bloom rate: {train[\"bloom_label\"].mean():.3f}')\n",
    "print(f'  Val:   {len(val):,} rows | {val[\"date\"].min()} → {val[\"date\"].max()} | bloom rate: {val[\"bloom_label\"].mean():.3f}')\n",
    "print(f'  Test:  {len(test):,} rows | {test[\"date\"].min()} → {test[\"date\"].max()} | bloom rate: {test[\"bloom_label\"].mean():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8B: Visualize the split\n",
    "fig, ax = plt.subplots(figsize=(16, 4))\n",
    "\n",
    "ax.scatter(train['date'], [0]*len(train), alpha=0.3, s=5, c='steelblue', label=f'Train ({len(train):,})')\n",
    "ax.scatter(val['date'], [1]*len(val), alpha=0.3, s=5, c='orange', label=f'Val ({len(val):,})')\n",
    "ax.scatter(test['date'], [2]*len(test), alpha=0.3, s=5, c='crimson', label=f'Test ({len(test):,})')\n",
    "\n",
    "ax.axvline(train_end, color='black', linestyle='--', alpha=0.5)\n",
    "ax.axvline(val_end, color='black', linestyle='--', alpha=0.5)\n",
    "ax.set_yticks([0, 1, 2])\n",
    "ax.set_yticklabels(['Train', 'Val', 'Test'])\n",
    "ax.set_title('Temporal Train/Val/Test Split')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Save Research Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9A: Save the unified research dataset\n",
    "output_dir = DATA_DIR / 'research'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "research_df.to_parquet(output_dir / 'unified_research_dataset.parquet', index=False)\n",
    "train.to_parquet(output_dir / 'train.parquet', index=False)\n",
    "val.to_parquet(output_dir / 'val.parquet', index=False)\n",
    "test.to_parquet(output_dir / 'test.parquet', index=False)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'created': datetime.now().isoformat(),\n",
    "    'total_records': len(research_df),\n",
    "    'train_records': len(train),\n",
    "    'val_records': len(val),\n",
    "    'test_records': len(test),\n",
    "    'train_end': str(train_end),\n",
    "    'val_end': str(val_end),\n",
    "    'lakes': research_df['lake'].unique().tolist(),\n",
    "    'features_insitu': ['chlorophyll_a', 'turbidity', 'dissolved_oxygen', 'ph',\n",
    "                        'temperature', 'conductivity', 'wind_speed', 'air_temperature', 'humidity'],\n",
    "    'features_satellite': ['ndvi', 'surface_temperature', 'chlorophyll_index',\n",
    "                           'turbidity_index', 'cloud_coverage',\n",
    "                           'reflectance_blue', 'reflectance_green',\n",
    "                           'reflectance_red', 'reflectance_nir'],\n",
    "    'label_binary': 'bloom_label',\n",
    "    'label_continuous': 'bloom_risk',\n",
    "    'bloom_positive_rate': float(research_df['bloom_label'].mean()),\n",
    "}\n",
    "\n",
    "with open(output_dir / 'dataset_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "\n",
    "print(f'Saved to {output_dir}/')\n",
    "print(f'  unified_research_dataset.parquet: {len(research_df):,} rows')\n",
    "print(f'  train.parquet: {len(train):,} rows')\n",
    "print(f'  val.parquet: {len(val):,} rows')\n",
    "print(f'  test.parquet: {len(test):,} rows')\n",
    "print(f'  dataset_metadata.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Quick Baseline: XGBoost (Monolithic)\n",
    "First baseline for RQ1 — single model using ALL available features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, brier_score_loss,\n",
    "                             classification_report, confusion_matrix, roc_curve, precision_recall_curve)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "\n",
    "# Define feature sets for experiment\n",
    "INSITU_FEATURES = ['chlorophyll_a', 'turbidity', 'dissolved_oxygen', 'ph',\n",
    "                   'temperature', 'conductivity', 'wind_speed', 'air_temperature', 'humidity']\n",
    "\n",
    "SATELLITE_FEATURES = ['ndvi', 'surface_temperature', 'chlorophyll_index',\n",
    "                      'turbidity_index', 'cloud_coverage']\n",
    "\n",
    "ALL_FEATURES = INSITU_FEATURES + SATELLITE_FEATURES\n",
    "\n",
    "TARGET = 'bloom_label'\n",
    "\n",
    "print(f'In-situ features ({len(INSITU_FEATURES)}): {INSITU_FEATURES}')\n",
    "print(f'Satellite features ({len(SATELLITE_FEATURES)}): {SATELLITE_FEATURES}')\n",
    "print(f'All features ({len(ALL_FEATURES)}): {ALL_FEATURES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10A: Prepare train/val/test matrices\n",
    "def prepare_Xy(df, features, target):\n",
    "    \"\"\"Extract feature matrix and labels, handling missing values.\"\"\"\n",
    "    available = [f for f in features if f in df.columns]\n",
    "    X = df[available].copy()\n",
    "    y = df[target].copy()\n",
    "    return X, y, available\n",
    "\n",
    "X_train, y_train, used_features = prepare_Xy(train, ALL_FEATURES, TARGET)\n",
    "X_val, y_val, _ = prepare_Xy(val, used_features, TARGET)\n",
    "X_test, y_test, _ = prepare_Xy(test, used_features, TARGET)\n",
    "\n",
    "# Impute + Scale\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "X_val_imp = imputer.transform(X_val)\n",
    "X_test_imp = imputer.transform(X_test)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_imp)\n",
    "X_val_scaled = scaler.transform(X_val_imp)\n",
    "X_test_scaled = scaler.transform(X_test_imp)\n",
    "\n",
    "print(f'Features used ({len(used_features)}): {used_features}')\n",
    "print(f'Train: X={X_train_scaled.shape}, y={y_train.shape} (bloom rate: {y_train.mean():.3f})')\n",
    "print(f'Val:   X={X_val_scaled.shape}, y={y_val.shape} (bloom rate: {y_val.mean():.3f})')\n",
    "print(f'Test:  X={X_test_scaled.shape}, y={y_test.shape} (bloom rate: {y_test.mean():.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10B: Train baseline models\n",
    "results = {}\n",
    "\n",
    "# Model 1: Gradient Boosting (XGBoost-like)\n",
    "gb = GradientBoostingClassifier(n_estimators=200, max_depth=5, learning_rate=0.1,\n",
    "                                 subsample=0.8, random_state=42)\n",
    "gb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Model 2: Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Model 3: Ensemble (average of GB + RF)\n",
    "models = {\n",
    "    'GradientBoosting': gb,\n",
    "    'RandomForest': rf,\n",
    "}\n",
    "\n",
    "print('Models trained.')\n",
    "for name, model in models.items():\n",
    "    print(f'  {name}: {model.n_estimators} estimators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10C: Evaluate on validation set\n",
    "def evaluate_model(name, y_true, y_prob):\n",
    "    \"\"\"Compute research-relevant metrics.\"\"\"\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    metrics = {\n",
    "        'AUROC': roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else float('nan'),\n",
    "        'AUPRC': average_precision_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else float('nan'),\n",
    "        'Brier': brier_score_loss(y_true, y_prob),\n",
    "        'Accuracy': (y_pred == y_true).mean(),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "print(f'{\"Model\":<25s} {\"AUROC\":>8s} {\"AUPRC\":>8s} {\"Brier\":>8s} {\"Acc\":>8s}')\n",
    "print('-' * 60)\n",
    "\n",
    "ensemble_probs_val = np.zeros(len(y_val))\n",
    "ensemble_probs_test = np.zeros(len(y_test))\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_prob_val = model.predict_proba(X_val_scaled)[:, 1]\n",
    "    y_prob_test = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    ensemble_probs_val += y_prob_val / len(models)\n",
    "    ensemble_probs_test += y_prob_test / len(models)\n",
    "\n",
    "    m = evaluate_model(name, y_val, y_prob_val)\n",
    "    results[name] = m\n",
    "    print(f'{name:<25s} {m[\"AUROC\"]:>8.4f} {m[\"AUPRC\"]:>8.4f} {m[\"Brier\"]:>8.4f} {m[\"Acc\"]:>8.4f}')\n",
    "\n",
    "# Ensemble\n",
    "m_ens = evaluate_model('Ensemble', y_val, ensemble_probs_val)\n",
    "results['Ensemble_GB_RF'] = m_ens\n",
    "print(f'{\"Ensemble (GB+RF)\":<25s} {m_ens[\"AUROC\"]:>8.4f} {m_ens[\"AUPRC\"]:>8.4f} {m_ens[\"Brier\"]:>8.4f} {m_ens[\"Acc\"]:>8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10D: Test set evaluation (final numbers)\n",
    "print('\\n' + '=' * 60)\n",
    "print('TEST SET RESULTS (Final Baseline)')\n",
    "print('=' * 60)\n",
    "\n",
    "print(f'\\n{\"Model\":<25s} {\"AUROC\":>8s} {\"AUPRC\":>8s} {\"Brier\":>8s} {\"Acc\":>8s}')\n",
    "print('-' * 60)\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    m = evaluate_model(name, y_test, y_prob)\n",
    "    print(f'{name:<25s} {m[\"AUROC\"]:>8.4f} {m[\"AUPRC\"]:>8.4f} {m[\"Brier\"]:>8.4f} {m[\"Acc\"]:>8.4f}')\n",
    "\n",
    "m_test = evaluate_model('Ensemble', y_test, ensemble_probs_test)\n",
    "print(f'{\"Ensemble (GB+RF)\":<25s} {m_test[\"AUROC\"]:>8.4f} {m_test[\"AUPRC\"]:>8.4f} {m_test[\"Brier\"]:>8.4f} {m_test[\"Acc\"]:>8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10E: Visualization - ROC + PR curves + Feature importance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# ROC curve\n",
    "for name, model in models.items():\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    axes[0].plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})', linewidth=2)\n",
    "\n",
    "fpr_e, tpr_e, _ = roc_curve(y_test, ensemble_probs_test)\n",
    "auc_e = roc_auc_score(y_test, ensemble_probs_test)\n",
    "axes[0].plot(fpr_e, tpr_e, label=f'Ensemble (AUC={auc_e:.3f})', linewidth=2, linestyle='--')\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve (Test Set)')\n",
    "axes[0].legend()\n",
    "\n",
    "# PR curve\n",
    "for name, model in models.items():\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    prec, rec, _ = precision_recall_curve(y_test, y_prob)\n",
    "    ap = average_precision_score(y_test, y_prob)\n",
    "    axes[1].plot(rec, prec, label=f'{name} (AP={ap:.3f})', linewidth=2)\n",
    "\n",
    "prec_e, rec_e, _ = precision_recall_curve(y_test, ensemble_probs_test)\n",
    "ap_e = average_precision_score(y_test, ensemble_probs_test)\n",
    "axes[1].plot(rec_e, prec_e, label=f'Ensemble (AP={ap_e:.3f})', linewidth=2, linestyle='--')\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve (Test Set)')\n",
    "axes[1].legend()\n",
    "\n",
    "# Feature importance (from GB model)\n",
    "importances = gb.feature_importances_\n",
    "idx = np.argsort(importances)[::-1]\n",
    "axes[2].barh(range(len(used_features)), importances[idx], color='steelblue', edgecolor='white')\n",
    "axes[2].set_yticks(range(len(used_features)))\n",
    "axes[2].set_yticklabels([used_features[i] for i in idx])\n",
    "axes[2].set_xlabel('Feature Importance')\n",
    "axes[2].set_title('GradientBoosting Feature Importance')\n",
    "axes[2].invert_yaxis()\n",
    "\n",
    "plt.suptitle('RQ1 Baseline: Monolithic Model Performance', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10F: Save baseline results\n",
    "baseline_results = {\n",
    "    'experiment': 'RQ1_monolithic_baseline',\n",
    "    'date': datetime.now().isoformat(),\n",
    "    'dataset': {\n",
    "        'train_size': len(train),\n",
    "        'val_size': len(val),\n",
    "        'test_size': len(test),\n",
    "        'features': used_features,\n",
    "        'n_features': len(used_features),\n",
    "    },\n",
    "    'results': results,\n",
    "    'test_results': {\n",
    "        'ensemble_auroc': float(auc_e),\n",
    "        'ensemble_auprc': float(ap_e),\n",
    "        'ensemble_brier': float(m_test['Brier']),\n",
    "        'ensemble_accuracy': float(m_test['Accuracy']),\n",
    "    }\n",
    "}\n",
    "\n",
    "results_dir = PROJECT_ROOT / 'outputs' / 'research'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(results_dir / 'rq1_monolithic_baseline.json', 'w') as f:\n",
    "    json.dump(baseline_results, f, indent=2, default=str)\n",
    "\n",
    "# Save models\n",
    "with open(results_dir / 'baseline_gb.pkl', 'wb') as f:\n",
    "    pickle.dump(gb, f)\n",
    "with open(results_dir / 'baseline_rf.pkl', 'wb') as f:\n",
    "    pickle.dump(rf, f)\n",
    "with open(results_dir / 'baseline_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open(results_dir / 'baseline_imputer.pkl', 'wb') as f:\n",
    "    pickle.dump(imputer, f)\n",
    "\n",
    "print(f'Baseline results saved to {results_dir}/')\n",
    "print(f'\\nNext steps:')\n",
    "print(f'  1. Notebook 04: Modality dropout experiments (RQ1)')\n",
    "print(f'  2. Notebook 05: Agentic model comparison (RQ1)')\n",
    "print(f'  3. Notebook 06: Communication protocol experiments (RQ2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Data Audit Results\n",
    "| Dataset | Records | Features | Coverage | Quality |\n",
    "|---------|---------|----------|----------|---------|\n",
    "| ml_ready_data.csv | 53K | 10 | 2020-2025 | Check water_temp zeros |\n",
    "| in_situ (LUBW) | 49K | 23 | 2025 | Rich, detailed |\n",
    "| satellite | 8.7K | 24 | 2020-2025 | Spectral indices |\n",
    "| lake_json | varies | bloom labels | 2020-2025 | Has bloom_probability! |\n",
    "\n",
    "### Baseline Established\n",
    "- Monolithic GB + RF ensemble trained on in-situ + satellite features\n",
    "- Proper temporal train/val/test split\n",
    "- Research-standard metrics: AUROC, AUPRC, Brier, Accuracy\n",
    "\n",
    "### Next Notebooks\n",
    "- **04**: Modality dropout (remove satellite/insitu features, measure degradation)\n",
    "- **05**: Agentic model (run same data through SWIM agents, compare)\n",
    "- **06**: Communication protocol experiments (RQ2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}